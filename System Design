Modular Design
The project is divided into independent modules for
• Admin Login:
For authentication, Only authorized person will be allowed to upload the text docu-
ments to the directory. The Administrative module helps to customize, integrate and
control access to the upload page. To log on to the Administrative module using the
authorization AdminID and Administrative password for that document. The Admin-
istrative module enables you to use the module more efficiently and effectively.
• Text Uploading:
Admin select offline text documents and upload it to the text data directory Text
documents will be stored in the Text Document Directory Document module displays
the list of all documents that are uploaded in. It enables you to upload and attach files
for text mining.
• Word Search:
Word or Word-Pair will be searched in the cleaned data called corpus. User inputs
a word or word-Pair for Searching(Query) The Text document will be ranked on the
basis of frequency of searched word(Query). Search module allow users to navigate their
way around the text documents to perform indexing and ranking to determine which
are more relevant .
• Data Preprocessing and Corpus creation:
Preprocessing refers to the transforma-
tions applied to your data before feeding it to word frequency search. To clean the
entire text document and to make a corpus through series of process like Tokeniza-
tion,Normalization,stemming,lemmatization. As a result, System outputs cleaned data
called Corpus. the data preprocessing is done by using NLTK Which can provide Ease
of Use. The primary purpose of the toolkit is to allow students to concentrate on
building natural language processing (NLP) systems. The more time students must
spend learnin to use the toolkit, the less useful it is.Consistency. The toolkit should
use consistent data structures and interfaces.Extensibility. The toolkit should easily ac-
commodate new components, whether those components replicate or extend the toolkits
existing functionality. The toolkit should be structured in such a way that it is obvi-
ous where new extensions would fit into the toolkits infrastructure. Documentation.
The toolkit, its data structures, and its implementation all need to be carefully and
thoroughly documented. All nomenclature must be carefully chosen and consistently
used.Simplicity. The toolkit should structure the complexities of building NLP systems,
not hide them. Therefore, each class defined by the toolkit should be simple enough
that a student could implement it by the time they finish an introductory course in
computational linguistics. Modularity. The interaction between different components
of the toolkit should be kept to a minimum, using simple, well-defined interfaces. In
particular, it should be possible to complete individual projects using small parts of the

toolkit, without worrying about how they interact with the rest of the toolkit. This
allows students to learn how to use the toolkit incrementally throughout a course. Mod-
ularity also makes it easier to change and extend the toolkit.
• Filtering text documents:
Text documents collected according to the interests
and characteristics of the user. Display Ranked list of text document on the basis of
the frequency of the searched word(Query). Text documents are listed according to the
higher word frequency. Filtering selects the relevant documents for the user, according
to the word(query) frequency in the cleaned data.The cleaned data again under goes
stopword removal and the dictionary formation for the frequency calculation
• Recommendation:
Recommendation of keywords according to the most frequent
words from the first result of search for the next search. This module suggest and rec-
ommend 5 Keywords for further search based on the existing textdocument extracted
on the previous search..

Input Output Design
• Admin Login
INPUT: AdminID and Password OUTPUT: The Upload page is accessed by the Admin.
• Text Uploading:
INPUT: Offline Text Documents OUTPUT: Text documents will be stored in the Text
Document Directory.
• Word Search:
INPUT: Query which is a word or word-pair. OUTPUT: The Text document will
be ranked on the basis of frequency of searched word(Query).
• Data Preprocessing and Corpus creation: INPUT: Text Documents in Text Document
Directory. OUTPUT: Cleaned data called Corpus
• Filtering text documents: INPUT: Text Documents OUTPUT: Text documents are
listed according to the higher word frequency.
• Recommendation: INPUT: The list of word frequencies in the resulted Text Document
in the last search OUTPUT: Recommended 5 Keywords will be displayede
